---
title: "Stats Homework 6"
author: "Hanna Butsko"
date: "2023-10-21"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem 1
Part 1
```{r}
# Define a function die_roll that simulates rolling a die multiple times
# and calculates the rolling average of getting a 6 as the number of rolls increases.
die_roll <- function(reps, seed) {
  # Set the random seed for reproducibility
  set.seed(seed)
  
  # Create an empty vector to store the results of each roll
  die_6 <- numeric(reps)
  
  # Simulate rolling a six-sided die given number of times
  roll <- sample(1:6, reps, replace = TRUE)
  
  # Loop over each roll and calculate the rolling average of getting a 6
  for (i in 1:reps) {
    # Calculate the proportion of 6s in the rolls so far and save it in "die_6" vector
    die_6[i] <- mean(roll[1:i] == 6)
  }
  
  # Print the overall mean of getting a 6
  print(mean(die_6))
  
  # Create a line plot to visualize the rolling average of getting a 6 over time
  plot(die_6, col = 4, type = "l")
}
```

a) Observation for 5 rolls
After rolling the die 5 times, we obtained a result of 0 indicating that the number 6 did not come up at all in those 5 rolls. This observation highlights that selecting a small number of rolls may not provide an accurate representation of the proportion of times we can expect to roll a 6. Let's now try with a larger number of rolls to get a more reliable estimate.
```{r}
# Call the die_roll function with 5 repetitions and seed of 1
die_roll(5, 1)
```

b) Observation for 100 rolls
Attempting 100 rolls yields a more accurate proportional estimate comparing to the previous graph. However, it is still challenging to see an exact proportion due to the jumpy nature of the plot. To get a more precise estimation, let's increase the number of rolls even further.
```{r}
# Call the die_roll function with 100 repetitions and seed of 1
die_roll(100, 1)
```

a) Observation for 10000 rolls
Here, we increased the number of rolls to 10,000. It becomes evident that selecting a larger number of rolls yields improved and clearer results. On the plot, we can observe that as the number of rolls increases, the proportion coefficient stabilizes at approximately 1.67, unaffected by individual die rolls.
```{r}
# Call the die_roll function with 10000 repetitions and seed of 1
die_roll(10000, 1)
```

Part 2
```{r}
# Define a function die_roll2 that simulates rolling a die multiple times
# and checks for a specific sequence of three consecutive 6s.
die_roll2 <- function(reps, seed) {
  # Set the random seed for reproducibility
  set.seed(seed)
  
  # Create an empty vector to store the results of each simulation
  rolls <- numeric(reps)
  
  # Loop over the specified number of repetitions
  for (i in 1:reps) {
    # Simulate rolling a six-sided die 100 times with replacement
    dice <- sample(1:6, 100, replace = TRUE)
    
    # Initialize a counter to keep track of consecutive 6s
    counter <- 0
    
    # Loop through the simulated dice rolls
    for (num in dice) {
      # Check if the current roll is a 6
      if (num == 6) {
        # If the current roll is a 6, add 1 to the counter
        counter <- counter + 1
      } else {
        # If the current roll is not a 6, reset the counter
        counter <- 0
      }
      
      # Check if we have observed three consecutive 6s
      if (counter == 3) {
        # If three consecutive 6s are observed, set the result to 1 and break the loop
        rolls[i] <- 1
        break
      }
    }
  }
  
  # Return the vector containing the results of each simulation
  return(rolls)
}

# Calculate the mean of the results from running die_roll2 with 10,000 repetitions and a seed of 1
mean(die_roll2(10000, 1))
```



# Problem 2
5.2
a) The reason why the friend got a probability of 0.7 for getting heads in a coin flip is because he didn't flip the coin a sufficient number of times. Flipping a coin only 10 times does not provide a realistic probability estimate because it doesn't allow for a statistically significant sample size, which can lead to unreliable results. To obtain a more accurate probability, a larger number of coin flips is essential to reduce the impact of random variation.
b) As mentioned in part a, it is essential to increase the sample size, in our case the number of coin flips, in order to get closer to the desired probability of 1/2.

5.16
a) The number of possible outcomes for our sample space will be equal to outcomes(True and False) to the power of questions(10 questions). So 2^10 = 1024
b) Getting at least one of the questions wrong cover all the possible outcomes except for one: the case where all 10 questions where answered correctly, the rest of the outcomes will have AT LEAST ONE of the questions answered wrong. So the complement will be 1/1024.
c) Based on what was explained in the previous question, the probability of getting at least one question wrong will cover all the outcomes except for one. In this case, to calculate the probability we can use the complement we already calculated and subtract it from 1. 1 - 1/1024 = 1023/1024 or approximately 0.999.

5.30
a) First, we would limit ourselves to the lowest income category space, disregarding other values that may distract us. Then, looking through the lowest income row, we observe two values: one representing probability of being audited, and the other one not. The question is asking to find the probability of being audited, so we would select the second value corresponding to "yes" which is 0.0085. Now, to obtain the conditional probability, we need to divide 0.0085 by the row marginal total probability, which would be 0.0085/(0.0085 + 0.9556) = 0.0088. Tax payer has 0.9 % chance to be audited given that they are in lowest income category.
```{r}
0.0085/(0.0085 + 0.9556)
```
b) Similar to the first question, we will limit ourselves to "yes" audited column. The value we are interested in is in lowest income category row, which is 0.0085. Now, we need to calculate row's marginal total probability, which would be 0.0085 + 0.0009 + 0.0003 = 0.0097. Now find the proportion: 0.0085/0.0097 = 0.8763. Given that the taxpayer was audited, they have 88 % chance to be in lowest income category.
```{r}
0.0085 / 0.0097
```

5.31
a) The number of individuals in this survey that identify as Christians is: 57.199 + 36.148 + 16.834 + 11.366 + 51.855 = 173.402. To find the probability that a randomly selected individual is identified as Christian, we would divide number pf Christians in the study by a total number of participants. 173.402 / 228.182 =  0.7599. 
The probability that a randomly selected individual is identified as Christian is 76 %.
```{r}
173.402 / 228.182 
```
b) To find the probability that the person is Catholic, given that they identify as Christian, we would calculate it by dividing the number of Catholics by the total number of Christians: 57.199 / 173.402 = 0.3299. 
The probability that an individual is Catholic is 33 % when they identify as Christian.
```{r}
57.199 / 173.402
```
c) To answer this question, we will first find the total number of individuals that answered: 228.182 - 11.815(refused to answer) = 216.367. Now, we will divide the number of individuals that identify as following no religion by the total number of individuals that answered: 34.169 / 216.367 = 0.1579.
Given that individual answered, the probability of that individual to identify as following no religion is 16 %.
```{r}
34.169 / 216.367
```

